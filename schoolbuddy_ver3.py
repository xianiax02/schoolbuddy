import os
import io
import time
import json
import boto3
import psycopg2
import requests
import pandas as pd  # ì‹œê°í™”ë¥¼ ìœ„í•´ ì¶”ê°€
import streamlit as st
import google.generativeai as genai
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from bs4 import BeautifulSoup

# LangChain ë° AWS ì—°ë™
from langchain_aws import BedrockEmbeddings

load_dotenv()

# --- [1] ì„œë¹„ìŠ¤ ë° ë³´ì•ˆ ì„¤ì • ---
GENAI_API_KEY = os.getenv("GENAI_API_KEY")
genai.configure(api_key=GENAI_API_KEY)
MODEL_NAME = 'models/gemini-2.5-flash'

@st.cache_resource
def init_aws():
    region = "us-west-2" 
    bedrock = boto3.client("bedrock-runtime", region_name=region)
    s3 = boto3.client('s3', region_name=region)
    return bedrock, s3

@st.cache_resource
def get_embeddings_model():
    bedrock, _ = init_aws()
    return BedrockEmbeddings(client=bedrock, model_id="amazon.titan-embed-text-v1")

def get_db_conn():
    try:
        return psycopg2.connect(
            host=os.getenv('DB_HOST'), database=os.getenv('DB_NAME'),
            user=os.getenv('DB_USER'), password=os.getenv('DB_PASSWORD'),
            port='5432', connect_timeout=3
        )
    except: return None

bedrock, s3 = init_aws()

# --- [2] í•µì‹¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

# ê´€ë¦¬ììš©: ë¡œê·¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_logs():
    conn = get_db_conn()
    if conn:
        try:
            # ì»¬ëŸ¼ëª…ì„ created_at -> clicked_at ìœ¼ë¡œ ë³€ê²½
            query = "SELECT user_lang, program_title, program_link, clicked_at FROM program_logs"
            df = pd.read_sql(query, conn)
            conn.close()
            return df
        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

@st.cache_data(show_spinner=False, ttl=3600)
def translate_content(raw_json_str, target_lang):
    if target_lang == "í•œêµ­ì–´ (Korean)":
        return json.loads(raw_json_str)
    
    model = genai.GenerativeModel(
        MODEL_NAME,
        generation_config={"response_mime_type": "application/json"}
    )
    
    prompt = f"""
    You are a professional JSON translation engine. 
    Translate the following JSON string into {target_lang}.
    Rules:
    - Translate ONLY the string values.
    - Preserve the original JSON structure and all keys ('title', 'summary', 'details') exactly.
    - Return valid JSON ONLY.
    
    JSON:
    {raw_json_str}
    """
    try:
        response = model.generate_content(prompt)
        return json.loads(response.text)
    except Exception as e:
        return json.loads(raw_json_str)

def log_interaction(title, link):
    conn = get_db_conn()
    if conn:
        try:
            cur = conn.cursor()
            cur.execute(
                "INSERT INTO program_logs (user_lang, program_title, program_link) VALUES (%s, %s, %s)",
                (st.session_state.language, title, link)
            )
            conn.commit(); cur.close(); conn.close()
        except: pass

@st.cache_data(ttl=3600)
def fetch_external_programs():
    url = "https://www.liveinkorea.kr/web/lay1/bbs/S1T10C27/A/4/list.do"
    programs = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        items = soup.select(".tbl_type1_wrap dl.tbl_list_type1")
        for dl in items[:6]:
            title_tag = dl.select_one("dt a span.title")
            link_tag = dl.select_one("dt a")
            if title_tag and link_tag:
                title = title_tag.get_text(strip=True)
                href = link_tag.get('href', '')
                link = "https://www.liveinkorea.kr/web/lay1/bbs/S1T10C27/A/4/" + href
                date = "N/A"
                date_items = dl.select("dd ul.date_search li")
                if len(date_items) >= 2: date = date_items[1].get_text(strip=True)
                programs.append({"title": title, "link": link, "date": date})
        return programs
    except: return []

# --- [3] UI/UX ì„¤ì • ---
st.set_page_config(page_title="School Buddy", page_icon="ğŸ’", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'language' not in st.session_state: st.session_state.language = 'í•œêµ­ì–´ (Korean)'
if 'admin_mode' not in st.session_state: st.session_state.admin_mode = False

# ìµœìƒë‹¨ ê´€ë¦¬ì ìŠ¤ìœ„ì¹˜
col_t1, col_t2 = st.columns([8, 2])
with col_t2:
    st.session_state.admin_mode = st.toggle("ğŸ”’ Admin Mode", value=st.session_state.admin_mode)

lang_pack = {
    "í•œêµ­ì–´ (Korean)": {
        "title": "ğŸ  í•™êµ ì†Œì‹ ëŒ€ì‹œë³´ë“œ", "monitor_h3": "AI ê°€ì •í†µì‹ ë¬¸ ë¶„ì„", "monitor_p": "ìµœê·¼ ì†Œì‹ì„ í™•ì¸í•˜ì„¸ìš”.",
        "status": "ì‘ë™ì¤‘", "date": "ë‚ ì§œ", "sidebar_upload": "ìƒˆ ê³µì§€ ë“±ë¡", "upload_label": "PDF/ì´ë¯¸ì§€ ì„ íƒ",
        "chat_placeholder": "í•™êµ ìƒí™œì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”...", "btn_analyze": "ğŸš€ ë¶„ì„ ë° DB ì €ì¥",
        "menu_program": "ğŸŒŸ ë§ì¶¤ í”„ë¡œê·¸ë¨ ì¶”ì²œ", "prog_desc": "ë‹¤ëˆ„ë¦¬ ì§€ì›ì„¼í„°ì˜ ìµœì‹  í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.",
        "admin_title": "ğŸ“Š ì‹œìŠ¤í…œ ë¡œê·¸ ë¶„ì„"
    },
    "English": {
        "title": "ğŸ  News Dashboard", "monitor_h3": "AI Document Analysis", "monitor_p": "Check recent updates.",
        "status": "Active", "date": "Date", "sidebar_upload": "Upload Notice", "upload_label": "Select PDF/Image",
        "chat_placeholder": "Ask about school life...", "btn_analyze": "ğŸš€ Analyze & Save",
        "menu_program": "ğŸŒŸ Program Recommendations", "prog_desc": "Latest programs from Danuri Center.",
        "admin_title": "ğŸ“Š System Log Analysis"
    },
    # ... (ê¸°íƒ€ ì–¸ì–´ ìƒëµ)
}
curr_lang = lang_pack.get(st.session_state.language, lang_pack["í•œêµ­ì–´ (Korean)"])

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700&display=swap');
html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif !important; background-color: #0E1117 !important; color: #E0E0E0 !important; }
[data-testid="stSidebar"] { background-color: #161B22 !important; border-right: 1px solid #30363D !important; }
.notice-card { background-color: #1D1D1F !important; border-radius: 16px; padding: 1.5rem; margin-bottom: 1.2rem; border-left: 5px solid #FF9800; box-shadow: 0 4px 15px rgba(0,0,0,0.3); }
.mcp-monitor { background: rgba(46, 125, 50, 0.1); border-radius: 16px; padding: 1.2rem; display: flex; align-items: center; gap: 1rem; border: 1px solid #2E7D32; margin-bottom: 1.5rem; }
.admin-sidebar { background: #21262d; padding: 10px; border-radius: 10px; border: 1px solid #FF9800; margin-top: 20px; }
</style>
""", unsafe_allow_html=True)

if 'messages' not in st.session_state: st.session_state.messages = []
if 'current_page' not in st.session_state: st.session_state.current_page = 'dashboard'

# --- [4] ì‚¬ì´ë“œë°” ë¡œì§ ---
with st.sidebar:
    st.markdown("<div style='text-align: center;'><h1>ğŸ’</h1><h2>School Buddy</h2></div>", unsafe_allow_html=True)
    
    # ê´€ë¦¬ì ëª¨ë“œì¼ ë•Œ ì‚¬ì´ë“œë°” ìƒë‹¨ì— ì‹œê°í™” ëŒ€ì‹œë³´ë“œ í‘œì‹œ
    if st.session_state.admin_mode:
        st.markdown(f"### {curr_lang.get('admin_title', 'ğŸ“Š Admin Dashboard')}")
        df_logs = fetch_logs()
        if not df_logs.empty:
            # 1. í”„ë¡œê·¸ë¨ë³„ í´ë¦­ ìˆ˜ ì°¨íŠ¸
            st.write("ğŸ“ˆ **ì¸ê¸° í”„ë¡œê·¸ë¨ TOP 5**")
            top_programs = df_logs['program_title'].value_counts().head(5)
            st.bar_chart(top_programs)
            
            # 2. ì–¸ì–´ë³„ ì‚¬ìš©ì ë¶„í¬
            st.write("ğŸŒ **ì–¸ì–´ë³„ ì´ìš© í˜„í™©**")
            lang_dist = df_logs['user_lang'].value_counts()
            st.write(lang_dist)
            
            # 3. ìµœê·¼ ë¡œê·¸ ë°ì´í„° (ì •ë ¬ ê¸°ì¤€ì„ clicked_atìœ¼ë¡œ ë³€ê²½)
            with st.expander("ğŸ“„ ìƒì„¸ ë¡œê·¸ ë³´ê¸°"):
                # ì •ë ¬ ê¸°ì¤€ ì»¬ëŸ¼ëª…ë„ clicked_atìœ¼ë¡œ ìˆ˜ì •
                st.dataframe(df_logs.sort_values(by='clicked_at', ascending=False), use_container_width=True)
        else:
            st.info("ìˆ˜ì§‘ëœ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì¼ë°˜ ë©”ë‰´
        selected_lang = st.selectbox("ğŸŒ Language", options=list(lang_pack.keys()), index=list(lang_pack.keys()).index(st.session_state.language))
        if selected_lang != st.session_state.language:
            st.session_state.language = selected_lang
            st.rerun()
    
    st.markdown("---")
    if st.button("ğŸ  Dashboard", use_container_width=True): st.session_state.current_page = 'dashboard'
    if st.button("ğŸ’¬ AI Chat", use_container_width=True): st.session_state.current_page = 'chat'
    if st.button(f"{curr_lang['menu_program']}", use_container_width=True): st.session_state.current_page = 'programs'
    
    st.markdown("---")
    uploaded_file = st.file_uploader(curr_lang['upload_label'], type=['pdf', 'jpg', 'png', 'jpeg'], label_visibility="collapsed")
    
    if st.button(curr_lang['btn_analyze'], use_container_width=True, type="primary"):
        if uploaded_file:
            with st.spinner("ì´ë¯¸ì§€/PDF ë¶„ì„ ë° ì§€ì‹ ë² ì´ìŠ¤ ë“±ë¡ ì¤‘..."):
                file_bytes = uploaded_file.getvalue()
                file_name = uploaded_file.name
                file_ext = file_name.split('.')[-1].lower()
                s3.put_object(Bucket=os.getenv('BUCKET_NAME'), Key=f"raw/{file_name}", Body=file_bytes)
                
                try:
                    model = genai.GenerativeModel(MODEL_NAME)
                    extracted_text = ""

                    if file_ext in ['jpg', 'jpeg', 'png']:
                        image_part = {"mime_type": f"image/{file_ext.replace('jpg', 'jpeg')}", "data": file_bytes}
                        ocr_prompt = "ì´ ì´ë¯¸ì§€ì— í¬í•¨ëœ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì •í™•íˆ ì½ì–´ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•´ì¤˜."
                        ocr_res = model.generate_content([ocr_prompt, image_part])
                        extracted_text = ocr_res.text
                    else:
                        import pypdf
                        pdf_reader = pypdf.PdfReader(io.BytesIO(file_bytes))
                        extracted_text = "".join([p.extract_text() for p in pdf_reader.pages])

                    if extracted_text.strip():
                        analysis_prompt = f"Analyze notice. Respond in JSON ONLY. Fields: title, summary, details:{{date: 'YYYY-MM-DD'}}. Content: {extracted_text[:3000]}"
                        res = model.generate_content(analysis_prompt, generation_config={"response_mime_type": "application/json"})
                        s3.put_object(Bucket=os.getenv('BUCKET_NAME'), Key=f"analysis/{file_name}.json", Body=res.text)
                        
                        embeddings_model = get_embeddings_model()
                        chunks = [extracted_text[i:i+1000] for i in range(0, len(extracted_text), 800)]
                        conn = get_db_conn()
                        if conn:
                            cur = conn.cursor()
                            for chunk in chunks:
                                vector = embeddings_model.embed_query(chunk)
                                cur.execute(
                                    "INSERT INTO documents (content, embedding, metadata) VALUES (%s, %s, %s)",
                                    (chunk, vector, json.dumps({"source": file_name, "type": file_ext}))
                                )
                            conn.commit(); cur.close(); conn.close()
                        st.success("âœ… ë¶„ì„ ë° ì§€ì‹ ë² ì´ìŠ¤ ë“±ë¡ ì™„ë£Œ!")
                        st.rerun()
                    else:
                        st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e: st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")

# --- [5] ë©”ì¸ í™”ë©´ ë¡œì§ (ë³€ê²½ ì—†ìŒ) ---
# (ëŒ€ì‹œë³´ë“œ, ì±„íŒ…, í”„ë¡œê·¸ë¨ ì¶”ì²œ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤)
if st.session_state.current_page == 'dashboard':
    st.title(curr_lang["title"])
    st.markdown(f'<div class="mcp-monitor">ğŸ” <b>{curr_lang["monitor_h3"]}</b>: {curr_lang["monitor_p"]} <span style="margin-left:auto;">â— {curr_lang["status"]}</span></div>', unsafe_allow_html=True)
    
    try:
        response = s3.list_objects_v2(Bucket=os.getenv('BUCKET_NAME'), Prefix='analysis/')
        if 'Contents' in response:
            json_files = [obj for obj in response['Contents'] if obj['Key'].endswith('.json')]
            sorted_files = sorted(json_files, key=lambda x: x['LastModified'], reverse=True)
            for obj in sorted_files[:3]:
                file_obj = s3.get_object(Bucket=os.getenv('BUCKET_NAME'), Key=obj['Key'])
                raw_json_str = file_obj['Body'].read().decode('utf-8')
                data = translate_content(raw_json_str, st.session_state.language)
                st.markdown(f"""
                <div class="notice-card">
                    <h4>ğŸ“„ {data.get('title')}</h4>
                    <p>{data.get('summary')}</p>
                    <div style="font-size:0.85rem; color:#86868B;">ğŸ“… {curr_lang['date']}: <b>{data.get('details', {}).get('date')}</b></div>
                </div>
                """, unsafe_allow_html=True)
        else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e: st.error(f"S3 ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")

elif st.session_state.current_page == 'chat':
    st.title("ğŸ’¬ AI Chat")
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])
    if query := st.chat_input(curr_lang['chat_placeholder']):
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"): st.markdown(query)
        with st.chat_message("assistant"):
            with st.spinner("ì •ë³´ë¥¼ ë¶„ì„ ì¤‘..."):
                embeddings_model = get_embeddings_model()
                query_vector = embeddings_model.embed_query(query)
                conn = get_db_conn()
                context_text = ""
                if conn:
                    cur = conn.cursor()
                    cur.execute("SELECT content FROM documents ORDER BY embedding <-> %s::vector LIMIT 10", (query_vector,))
                    context_text = "\n\n".join([r[0] for r in cur.fetchall()])
                    cur.close(); conn.close()
                model = genai.GenerativeModel(MODEL_NAME)
                prompt = f"Answer in {st.session_state.language}. [Notice Context]:\n{context_text}\n\nQuestion: {query}"
                resp = model.generate_content(prompt)
                st.markdown(resp.text)
                st.session_state.messages.append({"role": "assistant", "content": resp.text})
                st.rerun()

elif st.session_state.current_page == 'programs':
    st.title(curr_lang['menu_program'])
    st.markdown(f"#### {curr_lang['prog_desc']}")
    programs = fetch_external_programs()
    if programs:
        for idx, pg in enumerate(programs):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.markdown(f'<div class="program-card"><b>{pg["title"]}</b><br><small>ğŸ“… {pg["date"]}</small></div>', unsafe_allow_html=True)
            with col2:
                if st.button("ğŸ”— ì´ë™", key=f"pg_{idx}", use_container_width=True):
                    log_interaction(pg['title'], pg['link'])
                    st.components.v1.html(f"<script>window.open('{pg['link']}')</script>", height=0)
            st.markdown("<br>", unsafe_allow_html=True)

st.markdown("<br><hr><p style='text-align:center; color:#86868B; font-size:0.8rem;'>Â© 2026 School Buddy | Integrated Intelligence v1.0</p>", unsafe_allow_html=True)