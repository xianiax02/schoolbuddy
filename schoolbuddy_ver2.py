import os
import io
import time
import json
import boto3
import psycopg2
import streamlit as st
import google.generativeai as genai
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# LangChain ë° AWS Bedrock ì—°ë™
from langchain_aws import BedrockEmbeddings

load_dotenv()

# --- [1] ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ---
GENAI_API_KEY = "AIzaSyDb5XkJtwn9fsmMdY5CVeX76ke0wUh5cUc"
genai.configure(api_key=GENAI_API_KEY)
MODEL_NAME = 'models/gemini-2.5-flash'

@st.cache_resource
def init_resources():
    region = "us-west-2" 
    bedrock = boto3.client("bedrock-runtime", region_name=region)
    s3 = boto3.client('s3', region_name=region)
    return bedrock, s3

def get_db_conn():
    try:
        return psycopg2.connect(
            host=os.getenv('DB_HOST'), 
            database=os.getenv('DB_NAME'),
            user=os.getenv('DB_USER'), 
            password=os.getenv('DB_PASSWORD'),
            port='5432', 
            connect_timeout=5
        )
    except Exception as e:
        st.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

bedrock, s3 = init_resources()

# --- [2] ì‹¤ì‹œê°„ ë²ˆì—­ ---
@st.cache_data(show_spinner=False, ttl=3600)
def translate_content(raw_json_str, target_lang):
    if target_lang == "í•œêµ­ì–´ (Korean)":
        return json.loads(raw_json_str)
    
    model = genai.GenerativeModel(MODEL_NAME)
    prompt = f"Translate this school notice JSON into {target_lang}. Respond ONLY with JSON. Data: {raw_json_str}"
    try:
        response = model.generate_content(prompt)
        res_text = response.text
        json_str = res_text[res_text.find('{'):res_text.rfind('}')+1]
        return json.loads(json_str)
    except:
        return json.loads(raw_json_str)

# --- [3] UI/UX ì„¤ì • ---
st.set_page_config(page_title="School Buddy", page_icon="ğŸ’", layout="wide")

if 'language' not in st.session_state:
    st.session_state.language = 'í•œêµ­ì–´ (Korean)'

lang_pack = {
    "í•œêµ­ì–´ (Korean)": {"title": "ğŸ  í•™êµ ì†Œì‹ ëŒ€ì‹œë³´ë“œ", "date": "ë‚ ì§œ", "sidebar_upload": "ìƒˆ ê³µì§€ ë“±ë¡", "upload_label": "PDF/ì´ë¯¸ì§€ ì„ íƒ", "chat_placeholder": "í•™êµ ìƒí™œì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”...", "btn_analyze": "ğŸš€ ë¶„ì„ ë° DB ì €ì¥"},
    "English": {"title": "ğŸ  School Dashboard", "date": "Date", "sidebar_upload": "Upload Notice", "upload_label": "Select PDF/Image", "chat_placeholder": "Ask about school life...", "btn_analyze": "ğŸš€ Analyze & Save"},
    "Tiáº¿ng Viá»‡t": {"title": "ğŸ  Báº£ng tin nhÃ  trÆ°á»ng", "date": "NgÃ y", "sidebar_upload": "ÄÄƒng kÃ½ thÃ´ng bÃ¡o", "upload_label": "Chá»n PDF/HÃ¬nh áº£nh", "chat_placeholder": "Há»i vá» cuá»™c sá»‘ng há»c Ä‘Æ°á»ng...", "btn_analyze": "ğŸš€ PhÃ¢n tÃ­ch & LÆ°u"},
    "ä¸­æ–‡": {"title": "ğŸ  å­¦æ ¡ä»ªè¡¨æ¿", "date": "æ—¥æœŸ", "sidebar_upload": "æ³¨å†Œé€šçŸ¥", "upload_label": "é€‰æ‹© PDF/å›¾åƒ", "chat_placeholder": "è¯¢é—®å­¦æ ¡ç”Ÿæ´»...", "btn_analyze": "ğŸš€ ë¶„ì„ ë° DB ì €ì¥"}
}
curr_lang = lang_pack.get(st.session_state.language, lang_pack["í•œêµ­ì–´ (Korean)"])

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700&display=swap');
html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif !important; background-color: #0E1117 !important; color: #E0E0E0 !important; }
[data-testid="stSidebar"] { background-color: #161B22 !important; border-right: 1px solid #30363D !important; }
.notice-card { background-color: #1D1D1F !important; border-radius: 16px; padding: 1.5rem; margin-bottom: 1.2rem; border-left: 5px solid #FF9800; }
</style>
""", unsafe_allow_html=True)

if 'messages' not in st.session_state: st.session_state.messages = []
if 'current_page' not in st.session_state: st.session_state.current_page = 'dashboard'

# --- [4] ì‚¬ì´ë“œë°”: ì¸ì œì…˜ (S3 + RDS Vector DB) ---
with st.sidebar:
    st.markdown("<div style='text-align: center;'><h1>ğŸ’</h1><h2>School Buddy</h2></div>", unsafe_allow_html=True)
    selected_lang = st.selectbox("ğŸŒ Language", options=list(lang_pack.keys()), index=list(lang_pack.keys()).index(st.session_state.language))
    if selected_lang != st.session_state.language:
        st.session_state.language = selected_lang
        st.rerun()
    
    st.markdown("---")
    if st.button("ğŸ  Dashboard", use_container_width=True): st.session_state.current_page = 'dashboard'
    if st.button("ğŸ’¬ AI Chat", use_container_width=True): st.session_state.current_page = 'chat'
    
    st.markdown("---")
    st.markdown(f"### ğŸ“„ {curr_lang['sidebar_upload']}")
    uploaded_file = st.file_uploader(curr_lang['upload_label'], type=['pdf', 'jpg', 'png', 'jpeg'], label_visibility="collapsed")
    
    if st.button(curr_lang['btn_analyze'], use_container_width=True, type="primary"):
        if uploaded_file:
            with st.spinner("AI ë¶„ì„ ë° ë²¡í„° ì €ì¥ ì¤‘..."):
                file_bytes = uploaded_file.getvalue()
                file_name = uploaded_file.name
                s3.put_object(Bucket=os.getenv('BUCKET_NAME'), Key=f"raw/{file_name}", Body=file_bytes)
                
                try:
                    model = genai.GenerativeModel(MODEL_NAME)
                    prompt = "Analyze this school notice. Respond in JSON ONLY. Fields: title, summary(2 sentences), details:{date: 'YYYY-MM-DD'}"
                    
                    if file_name.lower().endswith(('pdf')):
                        import pypdf
                        pdf_reader = pypdf.PdfReader(io.BytesIO(file_bytes))
                        full_text = "".join([p.extract_text() for p in pdf_reader.pages])
                        response = model.generate_content(f"{prompt}\n\nContent: {full_text[:5000]}")
                    else:
                        img_data = {'mime_type': 'image/jpeg', 'data': file_bytes}
                        response = model.generate_content([prompt, img_data])
                    
                    json_str = response.text[response.text.find('{'):response.text.rfind('}')+1]
                    s3.put_object(Bucket=os.getenv('BUCKET_NAME'), Key=f"analysis/{file_name}.json", Body=json_str)
                    
                    # ë²¡í„° ì„ë² ë”© ìƒì„± (Bedrock Titan)
                    analysis_data = json.loads(json_str)
                    # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì œëª©ê³¼ ìš”ì•½ì„ í•©ì³ì„œ ë²¡í„°í™” 
                    text_to_embed = f"ê³µì§€ ì œëª©: {analysis_data.get('title')}\nìš”ì•½: {analysis_data.get('summary')}"
                    embeddings_model = BedrockEmbeddings(client=bedrock, model_id="amazon.titan-embed-text-v1")
                    vector = embeddings_model.embed_query(text_to_embed)
                    
                    # RDSì— ë²¡í„° ë°ì´í„° ì €ì¥
                    conn = get_db_conn()
                    if conn:
                        cur = conn.cursor()
                        cur.execute(
                            "INSERT INTO documents (content, embedding, metadata) VALUES (%s, %s, %s)",
                            (text_to_embed, vector, json.dumps({"source": file_name, "date": analysis_data.get('details', {}).get('date')}))
                        )
                        conn.commit()
                        cur.close(); conn.close()
                    
                    st.success("âœ… RAG ì§€ì‹ ë² ì´ìŠ¤ ë“±ë¡ ì™„ë£Œ!")
                    st.rerun()
                except Exception as e: st.error(f"Error: {e}")

# --- [5] ëŒ€ì‹œë³´ë“œ ---
if st.session_state.current_page == 'dashboard':
    st.title(curr_lang["title"])
    try:
        response = s3.list_objects_v2(Bucket=os.getenv('BUCKET_NAME'), Prefix='analysis/')
        if 'Contents' in response:
            sorted_files = sorted([f for f in response['Contents'] if f['Key'] != 'analysis/'], key=lambda x: x['LastModified'], reverse=True)
            for obj in sorted_files[:5]:
                file_obj = s3.get_object(Bucket=os.getenv('BUCKET_NAME'), Key=obj['Key'])
                display_data = translate_content(file_obj['Body'].read().decode('utf-8'), st.session_state.language)
                st.markdown(f'<div class="notice-card"><h4>ğŸ“„ {display_data.get("title")}</h4><p>{display_data.get("summary")}</p><small>ğŸ“… {display_data.get("details", {}).get("date")}</small></div>', unsafe_allow_html=True)
    except: st.error("Data Error")

# --- [6] AI ì±„íŒ…: ì‹œë§¨í‹± ê²€ìƒ‰ ìµœì í™” ---
elif st.session_state.current_page == 'chat':
    st.title("ğŸ’¬ AI School Assistant")
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if query := st.chat_input(curr_lang['chat_placeholder']):
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"): st.markdown(query)

        with st.chat_message("assistant"):
            with st.spinner("ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # 1. ì§ˆë¬¸ ì„ë² ë”©
                embeddings_model = BedrockEmbeddings(client=bedrock, model_id="amazon.titan-embed-text-v1")
                query_vector = embeddings_model.embed_query(query)
                
                # 2. ë²¡í„° ê²€ìƒ‰ ê°•í™” (Top-K = 15) 
                conn = get_db_conn()
                context_text = ""
                if conn:
                    cur = conn.cursor()
                    # 15ê°œì˜ ë¬¸ë§¥ì„ ê°€ì ¸ì™€ì„œ ì´ë¦„ ëˆ„ë½ ë°©ì§€ 
                    cur.execute("SELECT content FROM documents ORDER BY embedding <-> %s::vector LIMIT 15", (query_vector,))
                    rows = cur.fetchall()
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ë§ì„ ë•Œ LLMì´ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ ìˆœì„œ ì •ë ¬ 
                    context_text = "\n\n".join([f"ê³µì§€ ë‚´ìš©: {r[0]}" for r in rows])
                    cur.close(); conn.close()

                # 3. ë‹µë³€ ìƒì„±: ê°€ì´ë“œë¼ì¸ ê°•í™” 
                model = genai.GenerativeModel(MODEL_NAME)
                prompt = f"""
                ë‹¹ì‹ ì€ í•™êµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë‹µë³€ ì–¸ì–´ëŠ” {st.session_state.language}ì…ë‹ˆë‹¤.
                ì•„ë˜ ì œê³µëœ [ê³µì§€ì‚¬í•­] ë‚´ìš©ì—ë§Œ ê·¼ê±°í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. 
                
                **ë‹µë³€ ê°€ì´ë“œ**:
                1. ë¬¸ì„œ ë‚´ì— êµ¬ì²´ì ì¸ ì•± ì´ë¦„ì´ë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ ëª…ì¹­ì´ 'ì œëª©'ì´ë‚˜ 'ë³¸ë¬¸'ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì² ì €íˆ í™•ì¸í•˜ì„¸ìš”.
                2. ì§ˆë¬¸ì—ì„œ ì˜ˆì‹œë¡œ ë“  ì´ë¦„ì´ ì•„ë‹Œ, ì‹¤ì œ [ê³µì§€ì‚¬í•­] í…ìŠ¤íŠ¸ ì•ˆì— ì¡´ì¬í•˜ëŠ” ê³ ìœ  ëª…ì‚¬ë¥¼ ë‹µí•˜ì„¸ìš”.
                3. ë§Œì•½ ê³µì§€ì‚¬í•­ì—ì„œ ë‘ ê°€ì§€ ì£¼ìš” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì†Œê°œí•˜ê³  ìˆë‹¤ë©´, ê·¸ ì´ë¦„ì„ ë°˜ë“œì‹œ ëª…ì‹œí•˜ì„¸ìš”.
                
                [ê³µì§€ì‚¬í•­]:
                {context_text}
                
                ì§ˆë¬¸: {query}
                """
                resp = model.generate_content(prompt)
                st.markdown(resp.text)
                st.session_state.messages.append({"role": "assistant", "content": resp.text})

st.markdown("<br><hr><p style='text-align:center; color:#86868B; font-size:0.8rem;'>Â© 2026 School Buddy | Full RAG Integration</p>", unsafe_allow_html=True)